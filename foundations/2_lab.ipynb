{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1afe9f39",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "373f13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae942fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6630de08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "#Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "\n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3baeb8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e7c8756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1963f1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would you assess the ethical implications of using artificial intelligence in decision-making processes that significantly impact socio-economic disparities, and what framework would you propose to ensure fairness and accountability?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad0b205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "464dd3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'How would you assess the ethical implications of using artificial intelligence in decision-making processes that significantly impact socio-economic disparities, and what framework would you propose to ensure fairness and accountability?'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a6feead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessing the ethical implications of using artificial intelligence (AI) in decision-making processes that impact socio-economic disparities is a complex task that involves various factors including bias, transparency, accountability, and societal values. Here’s a structured approach to evaluating these implications and a proposed framework to ensure fairness and accountability:\n",
      "\n",
      "### Ethical Implications\n",
      "\n",
      "1. **Bias and Discrimination**: AI systems can perpetuate or even exacerbate existing biases if they are trained on historical data that reflects socio-economic disparities. This can lead to unfair treatment of certain groups and reinforce systemic inequalities.\n",
      "\n",
      "2. **Transparency**: The decision-making processes of AI systems can be opaque, making it difficult for affected individuals to understand how decisions are made. This lack of transparency can erode trust and limit individuals' ability to contest unfair decisions.\n",
      "\n",
      "3. **Accountability**: Determining accountability for decisions made by AI systems is crucial. If an AI system makes a harmful decision, it can be challenging to hold a person or organization accountable.\n",
      "\n",
      "4. **Representation**: The development of AI technologies often lacks diversity in the teams creating these systems, which can lead to a narrow understanding of the problems being addressed and the populations being affected.\n",
      "\n",
      "5. **Impact on Employment and Opportunity**: The deployment of AI in areas such as hiring, credit scoring, or public service can result in job displacement or limited access to resources, thus widening socio-economic gaps.\n",
      "\n",
      "### Proposed Framework for Fairness and Accountability\n",
      "\n",
      "To effectively address the ethical implications of AI in decision-making, a comprehensive framework can be implemented, consisting of several key components:\n",
      "\n",
      "1. **Stakeholder Engagement**:\n",
      "   - Involve diverse stakeholders including affected communities, ethicists, data scientists, and policymakers in the design and implementation of AI systems to ensure varied perspectives are considered.\n",
      "\n",
      "2. **Bias Mitigation Strategies**:\n",
      "   - Conduct rigorous impact assessments that include tests for bias and establish protocols for mitigating biases in training data and algorithms. Techniques such as fairness auditing and adversarial testing can be employed.\n",
      "\n",
      "3. **Transparency and Explainability**:\n",
      "   - Develop clear guidelines for transparency, requiring organizations to disclose how AI systems make decisions and the data they use. Incorporate explainable AI techniques to improve understanding of AI outputs.\n",
      "\n",
      "4. **Accountability Mechanisms**:\n",
      "   - Establish clear accountability structures, specifying who is responsible for the outcomes of AI decisions. This could include regular reporting on AI system performance and social impact assessments.\n",
      "\n",
      "5. **Regulatory Compliance**:\n",
      "   - Align with existing regulations (like GDPR in Europe) and contribute to the development of new regulations aimed at ensuring ethical AI usage, with a focus on protecting vulnerable populations.\n",
      "\n",
      "6. **Ongoing Monitoring and Feedback**:\n",
      "   - Implement continuous monitoring systems to ensure AI systems adapt to changing societal values and norms. This includes creating feedback loops where affected individuals can report issues or concerns.\n",
      "\n",
      "7. **Education and Capacity Building**:\n",
      "   - Promote education and training for stakeholders in AI ethics, bias awareness, and data literacy to create a more informed society that can engage with and critique AI technologies.\n",
      "\n",
      "8. **Impact Measurement**:\n",
      "   - Regularly measure and report on the socio-economic impacts of AI usage, ensuring that organizations prioritize fairness and equity in their objectives.\n",
      "\n",
      "By adopting this framework, organizations can work towards ensuring that AI contributes positively to society by promoting fairness and accountability, thereby mitigating the risk of exacerbating socio-economic disparities. Regular reassessment and evolution of these measures will be essential as AI technologies and societal values continue to evolve.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "print(answer)\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0614e5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Assessing the ethical implications of using artificial intelligence (AI) in decision-making processes that impact socio-economic disparities is a complex task that involves various factors including bias, transparency, accountability, and societal values. Here’s a structured approach to evaluating these implications and a proposed framework to ensure fairness and accountability:\n",
       "\n",
       "### Ethical Implications\n",
       "\n",
       "1. **Bias and Discrimination**: AI systems can perpetuate or even exacerbate existing biases if they are trained on historical data that reflects socio-economic disparities. This can lead to unfair treatment of certain groups and reinforce systemic inequalities.\n",
       "\n",
       "2. **Transparency**: The decision-making processes of AI systems can be opaque, making it difficult for affected individuals to understand how decisions are made. This lack of transparency can erode trust and limit individuals' ability to contest unfair decisions.\n",
       "\n",
       "3. **Accountability**: Determining accountability for decisions made by AI systems is crucial. If an AI system makes a harmful decision, it can be challenging to hold a person or organization accountable.\n",
       "\n",
       "4. **Representation**: The development of AI technologies often lacks diversity in the teams creating these systems, which can lead to a narrow understanding of the problems being addressed and the populations being affected.\n",
       "\n",
       "5. **Impact on Employment and Opportunity**: The deployment of AI in areas such as hiring, credit scoring, or public service can result in job displacement or limited access to resources, thus widening socio-economic gaps.\n",
       "\n",
       "### Proposed Framework for Fairness and Accountability\n",
       "\n",
       "To effectively address the ethical implications of AI in decision-making, a comprehensive framework can be implemented, consisting of several key components:\n",
       "\n",
       "1. **Stakeholder Engagement**:\n",
       "   - Involve diverse stakeholders including affected communities, ethicists, data scientists, and policymakers in the design and implementation of AI systems to ensure varied perspectives are considered.\n",
       "\n",
       "2. **Bias Mitigation Strategies**:\n",
       "   - Conduct rigorous impact assessments that include tests for bias and establish protocols for mitigating biases in training data and algorithms. Techniques such as fairness auditing and adversarial testing can be employed.\n",
       "\n",
       "3. **Transparency and Explainability**:\n",
       "   - Develop clear guidelines for transparency, requiring organizations to disclose how AI systems make decisions and the data they use. Incorporate explainable AI techniques to improve understanding of AI outputs.\n",
       "\n",
       "4. **Accountability Mechanisms**:\n",
       "   - Establish clear accountability structures, specifying who is responsible for the outcomes of AI decisions. This could include regular reporting on AI system performance and social impact assessments.\n",
       "\n",
       "5. **Regulatory Compliance**:\n",
       "   - Align with existing regulations (like GDPR in Europe) and contribute to the development of new regulations aimed at ensuring ethical AI usage, with a focus on protecting vulnerable populations.\n",
       "\n",
       "6. **Ongoing Monitoring and Feedback**:\n",
       "   - Implement continuous monitoring systems to ensure AI systems adapt to changing societal values and norms. This includes creating feedback loops where affected individuals can report issues or concerns.\n",
       "\n",
       "7. **Education and Capacity Building**:\n",
       "   - Promote education and training for stakeholders in AI ethics, bias awareness, and data literacy to create a more informed society that can engage with and critique AI technologies.\n",
       "\n",
       "8. **Impact Measurement**:\n",
       "   - Regularly measure and report on the socio-economic impacts of AI usage, ensuring that organizations prioritize fairness and equity in their objectives.\n",
       "\n",
       "By adopting this framework, organizations can work towards ensuring that AI contributes positively to society by promoting fairness and accountability, thereby mitigating the risk of exacerbating socio-economic disparities. Regular reassessment and evolution of these measures will be essential as AI technologies and societal values continue to evolve."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1ecef42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/3xtnt0vx13q1n9pmf7ks_nhc0000gn/T/ipykernel_27750/2925935930.py:4: DeprecationWarning: The model 'claude-3-7-sonnet-latest' is deprecated and will reach end-of-life on February 19th, 2026.\n",
      "Please migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\n",
      "  response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Ethical Implications of AI in High-Impact Decision-Making\n",
       "\n",
       "The use of AI in decisions affecting socio-economic disparities presents several ethical concerns:\n",
       "\n",
       "**Potential harms:**\n",
       "- Algorithmic bias that reinforces existing inequalities\n",
       "- Lack of transparency creating \"black box\" decisions affecting vulnerable populations\n",
       "- Automation of discrimination through historical data patterns\n",
       "- Concentration of power in organizations controlling AI systems\n",
       "- Displacement of human judgment in complex social contexts\n",
       "\n",
       "**Potential benefits:**\n",
       "- Reduction of human bias when properly implemented\n",
       "- Scalable, consistent application of decision criteria\n",
       "- Data-driven identification of previously overlooked inequities\n",
       "- Enhanced efficiency in resource allocation\n",
       "\n",
       "## Proposed Framework for Fairness and Accountability\n",
       "\n",
       "1. **Pre-deployment requirements:**\n",
       "   - Diverse representation in development teams\n",
       "   - Rigorous bias testing across demographic groups\n",
       "   - Stakeholder consultation, particularly from affected communities\n",
       "\n",
       "2. **Technical safeguards:**\n",
       "   - Explainable AI approaches when possible\n",
       "   - Regular fairness audits against multiple definitions of fairness\n",
       "   - Preservation of human oversight in consequential decisions\n",
       "\n",
       "3. **Governance mechanisms:**\n",
       "   - Independent review boards with binding authority\n",
       "   - Legal liability frameworks for AI-related harms\n",
       "   - Mandatory impact assessments for high-risk applications\n",
       "\n",
       "4. **Continuous improvement:**\n",
       "   - Systematic monitoring for disparate impacts\n",
       "   - Clear pathways for contesting algorithmic decisions\n",
       "   - Regular retraining to address emerging biases\n",
       "\n",
       "What aspects of this framework would you like me to elaborate on further?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e3d673",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858440d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
